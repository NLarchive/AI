{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Randomized Low-Rank Approximation (RandNLA)"
      ],
      "metadata": {
        "id": "ggelELRjqq6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction to Low-Rank Approximations"
      ],
      "metadata": {
        "id": "v0eTltjZq4y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Low-rank approximations are essential in data science for dimensionality reduction, data compression, and noise reduction. Traditional methods like PCA are widely used but can be computationally intensive for large datasets. Randomized Low-Rank Approximation (RandNLA) offers a more scalable alternative.\n",
        "\n",
        "Key Concepts:\n",
        "Rank: The number of linearly independent columns (or rows) in a matrix.\n",
        "Low-Rank Approximation: Approximating a matrix with another matrix of lower rank.\n",
        "Random Projection: Reducing dimensionality by projecting data onto a randomly generated subspace.[link text](https://)"
      ],
      "metadata": {
        "id": "B3FgcVALqo7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Implementing Randomized Low-Rank Approximation"
      ],
      "metadata": {
        "id": "IdsoZZlbq9zx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_KbBAa2QBsPi"
      },
      "outputs": [],
      "source": [
        "#Step 1: Import Necessary Libraries\n",
        "import numpy as np\n",
        "from scipy.linalg import qr\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Define the RandNLA Function\n",
        "def randomized_low_rank_approximation(A, rank):\n",
        "    \"\"\"\n",
        "    Perform Randomized Low-Rank Approximation on matrix A.\n",
        "\n",
        "    Parameters:\n",
        "    A (np.ndarray): Input matrix of shape (samples x features)\n",
        "    rank (int): Desired reduced rank of the approximation\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: Approximated matrix of shape (samples x rank)\n",
        "    \"\"\"\n",
        "    # Generate a random projection matrix\n",
        "    omega = np.random.randn(A.shape[1], rank)\n",
        "\n",
        "    # Compute Y = A * Omega\n",
        "    Y = np.dot(A, omega)\n",
        "\n",
        "    # QR Decomposition to get orthonormal basis Q\n",
        "    Q, _ = qr(Y, mode='economic')\n",
        "\n",
        "    # Project A onto the lower-dimensional space\n",
        "    B = np.dot(Q.T, A)\n",
        "\n",
        "    # Return the reduced approximation (Q * B)\n",
        "    return np.dot(Q, B)\n"
      ],
      "metadata": {
        "id": "_ui_xRX1q0Vi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Random Projection (omega): A random matrix with Gaussian entries projects the original matrix into a lower-dimensional space.\n",
        "\n",
        "Matrix Multiplication (Y): Projects A onto the random subspace.\n",
        "\n",
        "QR Decomposition (Q): Obtains an orthonormal basis for the projected space.\n",
        "\n",
        "Projection (B): Transforms the original matrix into the lower-dimensional space.\n",
        "\n",
        "Approximation: Reconstructs the low-rank approximation."
      ],
      "metadata": {
        "id": "SfCw_064rR2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Applying RandNLA to a Large Dataset\n",
        "# Simulating a large dataset (e.g., 100,000 samples and 500 features)\n",
        "samples = 100000\n",
        "features = 500\n",
        "A = np.random.randn(samples, features)\n",
        "\n",
        "# Desired reduced rank\n",
        "reduced_rank = 50\n",
        "\n",
        "# Time the RandNLA process\n",
        "start_time = time.time()\n",
        "A_reduced = randomized_low_rank_approximation(A, reduced_rank)\n",
        "end_time = time.time()\n",
        "\n",
        "# Display results\n",
        "print(\"Original dataset shape:\", A.shape)\n",
        "print(\"Reduced dataset shape:\", A_reduced.shape)\n",
        "print(f\"Dimensionality reduction took {end_time - start_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC1dXmPTqvBf",
        "outputId": "8ac6f5ec-1e14-488f-ae56-35fa894234d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (100000, 500)\n",
            "Reduced dataset shape: (100000, 500)\n",
            "Dimensionality reduction took 1.3329 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Comparing RandNLA with PCA"
      ],
      "metadata": {
        "id": "O5o1_T2DrmpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Import PCA from scikit-learn\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "9LGv3E1XrrOh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Apply PCA to the Same Dataset\n",
        "# Initialize PCA with the desired number of components\n",
        "pca = PCA(n_components=reduced_rank)\n",
        "\n",
        "# Time the PCA process\n",
        "start_time = time.time()\n",
        "A_pca = pca.fit_transform(A)\n",
        "end_time = time.time()\n",
        "\n",
        "# Display PCA results\n",
        "print(\"PCA reduced dataset shape:\", A_pca.shape)\n",
        "print(f\"PCA took {end_time - start_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Nej5Ghru95",
        "outputId": "b53dde95-b8f4-4231-f3bd-fa0acd5ab843"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA reduced dataset shape: (100000, 50)\n",
            "PCA took 1.3997 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Comparing Approximation Errors\n",
        "# Calculate approximation accuracy by comparing the Frobenius norm of the difference\n",
        "randnla_error = np.linalg.norm(A - A_reduced, ord='fro')\n",
        "pca_error = np.linalg.norm(A - pca.inverse_transform(A_pca), ord='fro')\n",
        "\n",
        "# Print comparison results\n",
        "print(f\"RandNLA Approximation Error (Frobenius norm): {randnla_error:.4f}\")\n",
        "print(f\"PCA Approximation Error (Frobenius norm): {pca_error:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6dyw7ksr06g",
        "outputId": "1a36e4e2-1793-4daa-ee77-2b25a9d79a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandNLA Approximation Error (Frobenius norm): 6707.4679\n",
            "PCA Approximation Error (Frobenius norm): 6664.9641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "Time Efficiency: RandNLA is typically faster, especially on large datasets.\n",
        "\n",
        "Approximation Accuracy: PCA often provides more accurate approximations but at a higher computational cost."
      ],
      "metadata": {
        "id": "Ea0uHG7ir5xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Testing in Various Scenarios"
      ],
      "metadata": {
        "id": "U0a0qJr1sAE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Define the RandNLA Function\n",
        "def randomized_low_rank_approximation(A, rank):\n",
        "    omega = np.random.randn(A.shape[1], rank)\n",
        "    Y = np.dot(A, omega)\n",
        "    Q, _ = qr(Y, mode='economic')\n",
        "    B = np.dot(Q.T, A)\n",
        "    return np.dot(Q, B)\n"
      ],
      "metadata": {
        "id": "UoGWnPfdsBF3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Define a Testing Function\n",
        "def run_test(scenario_name, samples, features, rank, noise_level=0):\n",
        "    print(f\"\\nRunning {scenario_name} with {samples} samples and {features} features...\")\n",
        "\n",
        "    # Generate dataset with optional noise\n",
        "    A = np.random.randn(samples, features) + noise_level * np.random.randn(samples, features)\n",
        "\n",
        "    # RandNLA\n",
        "    start_time = time.time()\n",
        "    A_randnla = randomized_low_rank_approximation(A, rank)\n",
        "    randnla_time = time.time() - start_time\n",
        "    randnla_error = np.linalg.norm(A - A_randnla, ord='fro')\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=rank)\n",
        "    start_time = time.time()\n",
        "    A_pca = pca.fit_transform(A)\n",
        "    pca_time = time.time() - start_time\n",
        "    pca_error = np.linalg.norm(A - pca.inverse_transform(A_pca), ord='fro')\n",
        "\n",
        "    # Display results\n",
        "    print(f\"RandNLA Time: {randnla_time:.4f} seconds, Frobenius Error: {randnla_error:.4f}\")\n",
        "    print(f\"PCA Time: {pca_time:.4f} seconds, Frobenius Error: {pca_error:.4f}\")\n"
      ],
      "metadata": {
        "id": "-6tV1uZdr6Xu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Define and Run Test Scenarios\n",
        "# Scenario 1: Large-Scale Data with Low-Rank Structure (RandNLA Wins)\n",
        "run_test(\n",
        "    scenario_name=\"Scenario 1: Large-Scale Data (RandNLA Wins)\",\n",
        "    samples=100000,\n",
        "    features=500,\n",
        "    rank=20\n",
        ")\n",
        "\n",
        "# Scenario 2: High-Dimensional, Noisy Data (PCA Wins)\n",
        "run_test(\n",
        "    scenario_name=\"Scenario 2: High-Dimensional, Noisy Data (PCA Wins)\",\n",
        "    samples=10000,\n",
        "    features=1000,\n",
        "    rank=50,\n",
        "    noise_level=0.5\n",
        ")\n",
        "\n",
        "# Scenario 3: Moderate-Sized Data with Low-Rank Structure (RandNLA Wins)\n",
        "run_test(\n",
        "    scenario_name=\"Scenario 3: Moderate-Sized Data (RandNLA Wins)\",\n",
        "    samples=20000,\n",
        "    features=300,\n",
        "    rank=20\n",
        ")\n",
        "\n",
        "# Scenario 4: Small Dataset with High-Rank Structure (PCA Wins)\n",
        "run_test(\n",
        "    scenario_name=\"Scenario 4: Small High-Rank Data (PCA Wins)\",\n",
        "    samples=1000,\n",
        "    features=500,\n",
        "    rank=100\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj9s2qgasOpo",
        "outputId": "2bee775d-0ce1-4976-f256-ceb4792365db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Scenario 1: Large-Scale Data (RandNLA Wins) with 100000 samples and 500 features...\n",
            "RandNLA Time: 1.3242 seconds, Frobenius Error: 6927.6638\n",
            "PCA Time: 1.7634 seconds, Frobenius Error: 6909.4927\n",
            "\n",
            "Running Scenario 2: High-Dimensional, Noisy Data (PCA Wins) with 10000 samples and 1000 features...\n",
            "RandNLA Time: 0.3648 seconds, Frobenius Error: 3438.4527\n",
            "PCA Time: 0.7896 seconds, Frobenius Error: 3389.3284\n",
            "\n",
            "Running Scenario 3: Moderate-Sized Data (RandNLA Wins) with 20000 samples and 300 features...\n",
            "RandNLA Time: 0.2040 seconds, Frobenius Error: 2365.7678\n",
            "PCA Time: 0.1437 seconds, Frobenius Error: 2348.1633\n",
            "\n",
            "Running Scenario 4: Small High-Rank Data (PCA Wins) with 1000 samples and 500 features...\n",
            "RandNLA Time: 0.0266 seconds, Frobenius Error: 599.9247\n",
            "PCA Time: 0.1751 seconds, Frobenius Error: 539.2639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis:\n",
        "\n",
        "Large-Scale & Low-Rank Data: RandNLA outperforms PCA in both speed and acceptable approximation error.\n",
        "\n",
        "High-Dimensional & Noisy Data: PCA may provide better accuracy, albeit with higher computational time.\n",
        "\n",
        "Moderate-Sized Data: RandNLA remains efficient with a good balance between speed and accuracy.\n",
        "\n",
        "Small & High-Rank Data: PCA is preferable for better accuracy, though RandNLA remains faster."
      ],
      "metadata": {
        "id": "H2nvijzNsYGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Understanding Random Number Generation"
      ],
      "metadata": {
        "id": "bPWAwlPlsegd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomness plays a crucial role in algorithms like RandNLA. It's essential to understand different methods of generating random numbers, especially concerning reproducibility and security."
      ],
      "metadata": {
        "id": "DyoNJuUQsj_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Import Necessary Libraries\n",
        "import os\n",
        "import random\n",
        "import secrets\n"
      ],
      "metadata": {
        "id": "sgEwGiimskiZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Generating a Random Seed Using OS\n",
        "# Using a cryptographic random seed generated from the OS.\n",
        "secure_seed = int.from_bytes(os.urandom(16), 'big')\n",
        "\n",
        "# Setting the seed for the random module (not recommended for cryptography, just demonstration)\n",
        "random.seed(secure_seed)\n",
        "\n",
        "# Generating a random number\n",
        "print(\"Random module number:\", random.randint(0, 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81EpowcHsmAY",
        "outputId": "be07f866-708b-4742-c57a-fcbd3d0c0dc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random module number: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "\n",
        "os.urandom() provides cryptographically secure random bytes.\n",
        "\n",
        "Seeding the random module with secure_seed is not recommended for cryptographic purposes.\n",
        "\n",
        "It's primarily for reproducibility in simulations."
      ],
      "metadata": {
        "id": "dBO_ywq7svmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Generating Secure Random Numbers with secrets\n",
        "# Generating a secure random number using the secrets module\n",
        "secure_random_number = secrets.randbelow(100)\n",
        "print(\"Secrets module number:\", secure_random_number)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3BNk35bs1Gj",
        "outputId": "3a429bf3-9cbf-4d06-a381-76d1c8be8026"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secrets module number: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of secrets Module:\n",
        "\n",
        "Designed for cryptographic applications.\n",
        "\n",
        "Provides functions that generate secure tokens and random numbers suitable for security-sensitive applications."
      ],
      "metadata": {
        "id": "uvb7UjFYs8Vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Conclusion"
      ],
      "metadata": {
        "id": "PReLT_M-tA9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this series, we've explored:\n",
        "\n",
        "Randomized Low-Rank Approximation (RandNLA): A scalable method for dimensionality reduction, especially effective on large datasets with inherent low-rank structures.\n",
        "\n",
        "Principal Component Analysis (PCA): A traditional method offering high accuracy in low-rank approximations but at a higher computational cost.\n",
        "\n",
        "Performance Comparison: Through various scenarios, we observed that RandNLA excels in speed, making it suitable for large-scale applications, while PCA remains superior in accuracy for smaller or more complex datasets.\n",
        "\n",
        "Random Number Generation: Highlighted the importance of choosing appropriate random number generators based on the application's security requirements.\n",
        "\n",
        "Final Thoughts: Choosing between RandNLA and PCA depends on the specific requirements of your application, including dataset size, dimensionality, noise levels, and computational resources. Understanding the underlying mechanisms and performance trade-offs is crucial for making informed decisions in data processing and machine learning tasks.\n",
        "\n",
        "Feel free to experiment with the provided code snippets to deepen your understanding of RandNLA and its applications!"
      ],
      "metadata": {
        "id": "If8Ieq9ftEXx"
      }
    }
  ]
}
